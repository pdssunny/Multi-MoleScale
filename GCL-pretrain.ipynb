{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f982635-1fcc-44b5-8d29-fc8596723515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "from rdkit import Chem\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, file = None, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "        self.file = file\n",
    "        # print(root) # MYdata\n",
    "        # print(self.data) # Data(x=[3, 1], edge_index=[2, 4], y=[3])\n",
    "        # print(self.slices) # defaultdict(<class 'dict'>, {'x': tensor([0, 3, 6]), 'edge_index': tensor([ 0,  4, 10]), 'y': tensor([0, 3, 6])})\n",
    "        # print(self.processed_paths[0]) # MYdata\\processed\\datas.pt\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # pass \n",
    "        return []\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['datas.pt']\n",
    "    # download\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(file)\n",
    "        smiles = df['SMILES'].tolist()\n",
    "        featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "        out = featurizer.featurize(smiles)\n",
    "\n",
    "        data_list = []\n",
    "        for i in range(len(out)):\n",
    "            edge_index = torch.tensor(out[i].edge_index)\n",
    "            x = torch.tensor(out[i].node_features, dtype=torch.float)\n",
    "            edge_node = torch.tensor(out[i].edge_features)\n",
    "            data = Data(x=x, edge_index=edge_index, edge_node = edge_node)\n",
    "            data_list.append(data)\n",
    "\n",
    "        # data_list = data_list.append(data)\n",
    "        if self.pre_filter is not None: \n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "        if self.pre_transform is not None: \n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "        data, slices = self.collate(data_list) \n",
    "        # print(data)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ccd98ad-3545-43b8-bdc5-c32afee2ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "path = \"MYdata\"\n",
    "file = \"pretrain-data.csv\"\n",
    "dataset = MyOwnDataset(path,file)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38449cc0-6cb7-4e11-bd12-280d8c418382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as osp\n",
    "import GCL.losses as L\n",
    "import GCL.augmentors as A\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from GCL.eval import get_split, SVMEvaluator\n",
    "from GCL.models import DualBranchContrast\n",
    "from torch_geometric.nn import GINConv, global_add_pool\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.datasets import TUDataset\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, precision_recall_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "407e5876-8c33-45d0-8546-313077cee1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gin_conv(input_dim, out_dim):\n",
    "    return GINConv(nn.Sequential(nn.Linear(input_dim, out_dim), nn.ReLU(), nn.Linear(out_dim, out_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c28694a-e59c-46ab-8444-233a6c28400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GConv(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers):\n",
    "        super(GConv, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.batch_norms = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            if i == 0:\n",
    "                self.layers.append(make_gin_conv(input_dim, hidden_dim))\n",
    "            else:\n",
    "                self.layers.append(make_gin_conv(hidden_dim, hidden_dim))\n",
    "            self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "\n",
    "        project_dim = hidden_dim * num_layers\n",
    "        self.project = torch.nn.Sequential(\n",
    "            nn.Linear(project_dim, project_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(project_dim, project_dim))\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        z = x\n",
    "        zs = []\n",
    "        for conv, bn in zip(self.layers, self.batch_norms):\n",
    "            z = conv(z, edge_index)\n",
    "            z = F.relu(z)\n",
    "            z = bn(z)\n",
    "            zs.append(z)\n",
    "        gs = [global_add_pool(z, batch) for z in zs]\n",
    "        z, g = [torch.cat(x, dim=1) for x in [zs, gs]]\n",
    "        return z, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "717888fd-2e97-41d6-af53-236fd4f1a6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, encoder, augmentor):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.augmentor = augmentor\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        aug1, aug2 = self.augmentor\n",
    "        x1, edge_index1, edge_weight1 = aug1(x, edge_index)\n",
    "        x2, edge_index2, edge_weight2 = aug2(x, edge_index)\n",
    "        z, g = self.encoder(x, edge_index, batch)\n",
    "        z1, g1 = self.encoder(x1, edge_index1, batch)\n",
    "        z2, g2 = self.encoder(x2, edge_index2, batch)\n",
    "        return z, g, z1, z2, g1, g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4896d42-d98a-49e3-8982-a4d281a40e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder_model, contrast_model, dataloader, optimizer):\n",
    "    encoder_model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "\n",
    "        _, _, _, _, g1, g2 = encoder_model(data.x, data.edge_index.to(torch.long), data.batch)\n",
    "        g1, g2 = [encoder_model.encoder.project(g) for g in [g1, g2]]\n",
    "        loss = contrast_model(g1=g1, g2=g2, batch=data.batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3414744a-3967-40ab-8cf4-0f0302d94d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(encoder_model, dataloader):\n",
    "    encoder_model.eval()\n",
    "    x = []\n",
    "    y = []\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        if data.x is None:\n",
    "            num_nodes = data.batch.size(0)\n",
    "            data.x = torch.ones((num_nodes, 1), dtype=torch.float32, device=data.batch.device)\n",
    "        _, g, _, _, _, _ = encoder_model(data.x, data.edge_index.to(torch.long), data.batch)\n",
    "        x.append(g)\n",
    "        y.append(data.y)\n",
    "    x = torch.cat(x, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "\n",
    "    #split = get_split(num_samples=x.size()[0], train_ratio=0.8, test_ratio=0.1)\n",
    "    #result = SVMEvaluator()(x, y, split)\n",
    "    #return result\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ac75f470-b108-4881-b914-0c3a7dd9336f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    path = \"MYdata\"\n",
    "    dataset = MyOwnDataset(path)\n",
    "    dataloader = DataLoader(dataset, batch_size=128)\n",
    "    input_dim = max(dataset.num_features, 1)\n",
    "\n",
    "    aug1 = A.Identity()\n",
    "    aug2 = A.RandomChoice([A.RWSampling(num_seeds=1000, walk_length=10),\n",
    "                           A.NodeDropping(pn=0.25),\n",
    "                           A.FeatureMasking(pf=0.25),\n",
    "                           A.EdgeRemoving(pe=0.25)], 1)\n",
    "    gconv = GConv(input_dim=input_dim, hidden_dim=32, num_layers=2).to(device)\n",
    "    encoder_model = Encoder(encoder=gconv, augmentor=(aug1, aug2)).to(device)\n",
    "    contrast_model = DualBranchContrast(loss=L.InfoNCE(tau=0.2), mode='G2G').to(device)\n",
    "\n",
    "    optimizer = Adam(encoder_model.parameters(), lr=0.01)\n",
    "\n",
    "    with tqdm(total=100, desc='(T)') as pbar:\n",
    "        for epoch in range(1, 101):\n",
    "            loss = train(encoder_model, contrast_model, dataloader, optimizer)\n",
    "            pbar.set_postfix({'loss': loss})\n",
    "            pbar.update()\n",
    "    \n",
    "    torch.save(encoder_model,\"gclModel\") #保存训练好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "30e9a1d9-856c-43fb-a3fb-4f2ec2a658f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(T): 100%|████████████████████████████████████████████████████████████████| 100/100 [00:04<00:00, 24.95it/s, loss=1.32]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab530e7c-f3c3-4889-ba03-37a9d2b94f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph111",
   "language": "python",
   "name": "graph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
